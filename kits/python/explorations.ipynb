{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:39:43.846990Z",
     "iopub.status.busy": "2023-01-24T19:39:43.846545Z",
     "iopub.status.idle": "2023-01-24T19:39:45.768603Z",
     "shell.execute_reply": "2023-01-24T19:39:45.767534Z",
     "shell.execute_reply.started": "2023-01-24T19:39:43.846946Z"
    }
   },
   "outputs": [],
   "source": [
    "from luxai_s2.env import LuxAI_S2\n",
    "from luxai_s2.map.board import Board\n",
    "from luxai_s2.state import State\n",
    "from luxai_s2.map_generator.generator import GameMap\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_w_custom_board(environment, seed, custom_board):\n",
    "    environment.agents = environment.possible_agents[:]\n",
    "    environment.env_steps = 0\n",
    "    if seed is not None:\n",
    "        environment.seed_val = seed\n",
    "        environment.seed_rng = np.random.RandomState(seed=seed)\n",
    "    else:\n",
    "        environment.seed_val = np.random.randint(0, 2**32 - 1)\n",
    "        environment.seed_rng = np.random.RandomState(seed=environment.seed_val)\n",
    "    \n",
    "    environment.state: State = State(\n",
    "        seed_rng=environment.seed_rng,\n",
    "        seed=environment.seed_val,\n",
    "        env_cfg=environment.state.env_cfg,\n",
    "        env_steps=0,\n",
    "        board=custom_board,\n",
    "    )\n",
    "        \n",
    "    environment.max_episode_length = environment.env_cfg.max_episode_length\n",
    "    for agent in environment.possible_agents:\n",
    "        environment.state.units[agent] = OrderedDict()\n",
    "        environment.state.factories[agent] = OrderedDict()\n",
    "        if environment.collect_stats:\n",
    "            environment.state.stats[agent] = create_empty_stats()\n",
    "    obs = environment.state.get_obs()\n",
    "    observations = {agent: obs for agent in environment.agents}\n",
    "    return observations, environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:39:46.052351Z",
     "iopub.status.busy": "2023-01-24T19:39:46.051205Z",
     "iopub.status.idle": "2023-01-24T19:39:46.068702Z",
     "shell.execute_reply": "2023-01-24T19:39:46.067580Z",
     "shell.execute_reply.started": "2023-01-24T19:39:46.052316Z"
    }
   },
   "outputs": [],
   "source": [
    "# key-values of dict below should match attributes present in this class\n",
    "# https://github.com/aernesto/Lux-Design-S2/blob/adrian/luxai_s2/luxai_s2/config.py#L34\n",
    "environment_config = dict(\n",
    "    max_episode_length=1,  # how many total turns in game\n",
    "    CYCLE_LENGTH=50,\n",
    "    DAY_LENGTH=50,  # so no night\n",
    "    MAX_RUBBLE=0,  # disable rubble   \n",
    ")\n",
    "env = LuxAI_S2(**environment_config)\n",
    "\n",
    "custom_rubble = np.zeros((env.env_cfg.map_size,) * 2, dtype=np.int64)\n",
    "custom_ice = np.zeros_like(custom_rubble)\n",
    "custom_ore = np.zeros_like(custom_rubble)\n",
    "custom_symmetry = None\n",
    "custom_map_ = GameMap(custom_rubble, custom_ice, custom_ore, custom_symmetry)\n",
    "\n",
    "simple_board = Board(\n",
    "    seed=env.seed_rng.randint(0, 2**32 - 1, dtype=np.int64), \n",
    "    env_cfg=env.env_cfg,\n",
    "    existing_map=custom_map_\n",
    ")\n",
    "\n",
    "obs, env = reset_w_custom_board(env, seed=41, custom_board=simple_board)\n",
    "# source code of reset() method: \n",
    "# https://github.com/aernesto/Lux-Design-S2/blob/adrian/luxai_s2/luxai_s2/env.py#L175\n",
    "# obs = env.reset(seed=41) # resets an environment with a seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rc('font', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:39:53.800713Z",
     "iopub.status.busy": "2023-01-24T19:39:53.800017Z",
     "iopub.status.idle": "2023-01-24T19:39:54.158812Z",
     "shell.execute_reply": "2023-01-24T19:39:54.157933Z",
     "shell.execute_reply.started": "2023-01-24T19:39:53.800678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the environment so far with rgb_array to get a quick look at the map\n",
    "# dark orange - high rubble, light orange - low rubble\n",
    "# blue = ice, yellow = ore\n",
    "img = env.render(\"rgb_array\", width=640, height=640)\n",
    "f, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:40:06.897335Z",
     "iopub.status.busy": "2023-01-24T19:40:06.896924Z",
     "iopub.status.idle": "2023-01-24T19:40:06.909031Z",
     "shell.execute_reply": "2023-01-24T19:40:06.907824Z",
     "shell.execute_reply.started": "2023-01-24T19:40:06.897303Z"
    }
   },
   "outputs": [],
   "source": [
    "from lux.kit import obs_to_game_state, GameState, EnvConfig\n",
    "from luxai_s2.utils import animate\n",
    "from lux.utils import direction_to, my_turn_to_place_factory\n",
    "class Agent():\n",
    "    def __init__(self, player: str, env_cfg: EnvConfig) -> None:\n",
    "        self.player = player\n",
    "        self.opp_player = \"player_1\" if self.player == \"player_0\" else \"player_0\"\n",
    "        np.random.seed(0)\n",
    "        self.env_cfg: EnvConfig = env_cfg\n",
    "\n",
    "    def early_setup(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "        actions = dict()\n",
    "        # optionally convert observations to python objects with utility functions\n",
    "        game_state = obs_to_game_state(step, self.env_cfg, obs) \n",
    "        return actions\n",
    "\n",
    "    def act(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "        actions = dict()\n",
    "        game_state = obs_to_game_state(step, self.env_cfg, obs)\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:40:40.163980Z",
     "iopub.status.busy": "2023-01-24T19:40:40.163528Z",
     "iopub.status.idle": "2023-01-24T19:40:40.178043Z",
     "shell.execute_reply": "2023-01-24T19:40:40.176597Z",
     "shell.execute_reply.started": "2023-01-24T19:40:40.163946Z"
    }
   },
   "outputs": [],
   "source": [
    "def animate(imgs, _return=True):\n",
    "    # using cv2 to generate videos as moviepy doesn't work on kaggle notebooks\n",
    "    import cv2\n",
    "    import os\n",
    "    import string\n",
    "    import random\n",
    "    video_name = ''.join(random.choice(string.ascii_letters) for i in range(18))+'.webm'\n",
    "    height, width, layers = imgs[0].shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'VP90')\n",
    "    video = cv2.VideoWriter(video_name, fourcc, 10, (width,height))\n",
    "\n",
    "    for img in imgs:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        video.write(img)\n",
    "    video.release()\n",
    "    if _return:\n",
    "        from IPython.display import Video\n",
    "        return Video(video_name)\n",
    "def interact(env, agents, steps):\n",
    "    # reset our env\n",
    "    obs_ = env.state.get_obs()\n",
    "    obs = {agent: obs_ for agent in agents}\n",
    "    np.random.seed(0)\n",
    "    imgs = []\n",
    "    step = 0\n",
    "    # Note that as the environment has two phases, we also keep track a value called \n",
    "    # `real_env_steps` in the environment state. The first phase ends once `real_env_steps` is 0 and used below\n",
    "\n",
    "    # iterate until phase 1 ends\n",
    "    while env.state.real_env_steps < 0:\n",
    "        if step >= steps: break\n",
    "        actions = {}\n",
    "        for player in env.agents:\n",
    "            o = obs[player]\n",
    "            a = agents[player].early_setup(step, o)\n",
    "            actions[player] = a\n",
    "        step += 1\n",
    "        obs, rewards, dones, infos = env.step(actions)\n",
    "        imgs += [env.render(\"rgb_array\", width=640, height=640)]\n",
    "    done = False\n",
    "    while not done:\n",
    "        if step >= steps: break\n",
    "        actions = {}\n",
    "        for player in env.agents:\n",
    "            o = obs[player]\n",
    "            a = agents[player].act(step, o)\n",
    "            actions[player] = a\n",
    "        step += 1\n",
    "        obs, rewards, dones, infos = env.step(actions)\n",
    "        imgs += [env.render(\"rgb_array\", width=640, height=640)]\n",
    "        done = dones[\"player_0\"] and dones[\"player_1\"]\n",
    "    return animate(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:43:03.880088Z",
     "iopub.status.busy": "2023-01-24T19:43:03.879639Z",
     "iopub.status.idle": "2023-01-24T19:43:03.890188Z",
     "shell.execute_reply": "2023-01-24T19:43:03.888785Z",
     "shell.execute_reply.started": "2023-01-24T19:43:03.880053Z"
    }
   },
   "outputs": [],
   "source": [
    "def early_setup(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "    if step == 0:\n",
    "        # bid 0 to not waste resources bidding and declare as the default faction\n",
    "        # you can bid -n to prefer going second or n to prefer going first in placement\n",
    "        return dict(faction=\"AlphaStrike\", bid=0)\n",
    "    else:\n",
    "        game_state = obs_to_game_state(step, self.env_cfg, obs)\n",
    "        # factory placement period\n",
    "        \n",
    "        # how much water and metal you have in your starting pool to give to new factories\n",
    "        water_left = game_state.teams[self.player].water\n",
    "        metal_left = game_state.teams[self.player].metal\n",
    "        \n",
    "        # how many factories you have left to place\n",
    "        factories_to_place = game_state.teams[self.player].factories_to_place\n",
    "        # whether it is your turn to place a factory\n",
    "        my_turn_to_place = my_turn_to_place_factory(game_state.teams[self.player].place_first, step)\n",
    "        if factories_to_place > 0 and my_turn_to_place:\n",
    "            # we will spawn our factory in a random location with 150 metal and water if it is our turn to place\n",
    "            potential_spawns = np.array(list(zip(*np.where(obs[\"board\"][\"valid_spawns_mask\"] == 1))))\n",
    "            spawn_loc = potential_spawns[np.random.randint(0, len(potential_spawns))]\n",
    "            return dict(spawn=spawn_loc, metal=150, water=150)\n",
    "        return dict()\n",
    "Agent.early_setup = early_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:43:20.020710Z",
     "iopub.status.busy": "2023-01-24T19:43:20.020210Z",
     "iopub.status.idle": "2023-01-24T19:43:22.001899Z",
     "shell.execute_reply": "2023-01-24T19:43:22.000148Z",
     "shell.execute_reply.started": "2023-01-24T19:43:20.020674Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x30395056/'VP90' is not supported with codec id 167 and format 'webm / WebM'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"zcXVZXmFqcImyvlsqm.webm\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recreate our agents and run\n",
    "agents = {player: Agent(player, env.state.env_cfg) for player in env.agents}\n",
    "interact(env, agents, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:44:40.947100Z",
     "iopub.status.busy": "2023-01-24T19:44:40.946428Z",
     "iopub.status.idle": "2023-01-24T19:44:40.954802Z",
     "shell.execute_reply": "2023-01-24T19:44:40.953290Z",
     "shell.execute_reply.started": "2023-01-24T19:44:40.947044Z"
    }
   },
   "outputs": [],
   "source": [
    "from lux.kit import obs_to_game_state, GameState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:44:43.860828Z",
     "iopub.status.busy": "2023-01-24T19:44:43.860415Z",
     "iopub.status.idle": "2023-01-24T19:44:43.869445Z",
     "shell.execute_reply": "2023-01-24T19:44:43.867811Z",
     "shell.execute_reply.started": "2023-01-24T19:44:43.860796Z"
    }
   },
   "outputs": [],
   "source": [
    "def act(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "    actions = dict()\n",
    "    game_state: GameState = obs_to_game_state(step, self.env_cfg, obs)\n",
    "    factories = game_state.factories[self.player]\n",
    "    for unit_id, factory in factories.items():\n",
    "        if factory.power >= self.env_cfg.ROBOTS[\"HEAVY\"].POWER_COST and \\\n",
    "        factory.cargo.metal >= self.env_cfg.ROBOTS[\"HEAVY\"].METAL_COST:\n",
    "            actions[unit_id] = factory.build_heavy()\n",
    "    return actions\n",
    "Agent.act = act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:44:47.928300Z",
     "iopub.status.busy": "2023-01-24T19:44:47.927887Z",
     "iopub.status.idle": "2023-01-24T19:44:52.501069Z",
     "shell.execute_reply": "2023-01-24T19:44:52.499615Z",
     "shell.execute_reply.started": "2023-01-24T19:44:47.928266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3: player_0 tried to perform an action in the early phase when it is not its turn right now.\n",
      "-2: player_1 tried to perform an action in the early phase when it is not its turn right now.\n",
      "-1: player_0 tried to perform an action in the early phase when it is not its turn right now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x30395056/'VP90' is not supported with codec id 167 and format 'webm / WebM'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"YDgzwJMrGfwKUIYPvj.webm\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recreate our agents and run\n",
    "agents = {player: Agent(player, env.state.env_cfg) for player in env.agents}\n",
    "interact(env, agents, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:45:08.930205Z",
     "iopub.status.busy": "2023-01-24T19:45:08.929774Z",
     "iopub.status.idle": "2023-01-24T19:45:08.943356Z",
     "shell.execute_reply": "2023-01-24T19:45:08.941948Z",
     "shell.execute_reply.started": "2023-01-24T19:45:08.930170Z"
    }
   },
   "outputs": [],
   "source": [
    "from lux.utils import direction_to\n",
    "import sys\n",
    "def act(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "    actions = dict()\n",
    "    game_state = obs_to_game_state(step, self.env_cfg, obs)\n",
    "    factories = game_state.factories[self.player]\n",
    "    for unit_id, factory in factories.items():\n",
    "        if factory.power >= self.env_cfg.ROBOTS[\"HEAVY\"].POWER_COST and \\\n",
    "        factory.cargo.metal >= self.env_cfg.ROBOTS[\"HEAVY\"].METAL_COST:\n",
    "            actions[unit_id] = factory.build_heavy()\n",
    "            \n",
    "    # iterate over our units and have them mine the closest ice tile\n",
    "    units = game_state.units[self.player]\n",
    "    ice_map = game_state.board.ice # flip the board as it stores by rows then columns\n",
    "    ice_tile_locations = np.argwhere(ice_map == 1) # numpy magic to get the position of every ice tile\n",
    "    for unit_id, unit in units.items():\n",
    "        # compute the distance to each ice tile from this unit and pick the closest\n",
    "        ice_tile_distances = np.mean((ice_tile_locations - unit.pos) ** 2, 1)\n",
    "        closest_ice_tile = ice_tile_locations[np.argmin(ice_tile_distances)]\n",
    "        \n",
    "        # if we have reached the ice tile, start mining if possible\n",
    "        if np.all(closest_ice_tile == unit.pos):\n",
    "            if unit.power >= unit.dig_cost(game_state) + unit.action_queue_cost(game_state):\n",
    "                actions[unit_id] = [unit.dig(repeat=0)]\n",
    "        else:\n",
    "            direction = direction_to(unit.pos, closest_ice_tile)\n",
    "            move_cost = unit.move_cost(game_state, direction)\n",
    "            # check move_cost is not None, meaning that direction is not off the map or blocked\n",
    "            # check if unit has enough power to move in addition to updating the action queue.\n",
    "            if move_cost is not None and unit.power >= move_cost + unit.action_queue_cost(game_state):\n",
    "                actions[unit_id] = [unit.move(direction, repeat=0)]\n",
    "        # since we are using the simple embedded visualizer, we will have to print out details about units\n",
    "        # importantly, note that we print with file=sys.stderr. Printing with anything will cause your agent to fail\n",
    "        if unit.cargo.ice > 50:\n",
    "            print(game_state.real_env_steps, unit, f\"has {unit.cargo.ice} ice\", file=sys.stderr)\n",
    "    return actions\n",
    "Agent.act = act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:45:13.579154Z",
     "iopub.status.busy": "2023-01-24T19:45:13.578713Z",
     "iopub.status.idle": "2023-01-24T19:45:20.806279Z",
     "shell.execute_reply": "2023-01-24T19:45:20.804924Z",
     "shell.execute_reply.started": "2023-01-24T19:45:13.579119Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No actions given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# recreate our agents and run\u001b[39;00m\n\u001b[1;32m      2\u001b[0m agents \u001b[38;5;241m=\u001b[39m {player: Agent(player, env\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39menv_cfg) \u001b[38;5;28;01mfor\u001b[39;00m player \u001b[38;5;129;01min\u001b[39;00m env\u001b[38;5;241m.\u001b[39magents}\n\u001b[0;32m----> 3\u001b[0m \u001b[43minteract\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 49\u001b[0m, in \u001b[0;36minteract\u001b[0;34m(env, agents, steps)\u001b[0m\n\u001b[1;32m     47\u001b[0m     actions[player] \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m     48\u001b[0m step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 49\u001b[0m obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m imgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [env\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m)]\n\u001b[1;32m     51\u001b[0m done \u001b[38;5;241m=\u001b[39m dones[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayer_0\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m dones[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayer_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/lux310/lib/python3.10/site-packages/luxai_s2/env.py:762\u001b[0m, in \u001b[0;36mLuxAI_S2.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;66;03m# If a user passes in actions with no agents, then just return empty observations, etc.\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m actions:\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo actions given\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, {}, {}, {}\n",
      "\u001b[0;31mValueError\u001b[0m: No actions given"
     ]
    }
   ],
   "source": [
    "# recreate our agents and run\n",
    "agents = {player: Agent(player, env.state.env_cfg) for player in env.agents}\n",
    "interact(env, agents, steps=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:45:43.271329Z",
     "iopub.status.busy": "2023-01-24T19:45:43.269909Z",
     "iopub.status.idle": "2023-01-24T19:45:43.293813Z",
     "shell.execute_reply": "2023-01-24T19:45:43.292379Z",
     "shell.execute_reply.started": "2023-01-24T19:45:43.271269Z"
    }
   },
   "outputs": [],
   "source": [
    "def act(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "    actions = dict()\n",
    "    game_state = obs_to_game_state(step, self.env_cfg, obs)\n",
    "    factories = game_state.factories[self.player]\n",
    "    factory_tiles, factory_units = [], []\n",
    "    for unit_id, factory in factories.items():\n",
    "        if factory.power >= self.env_cfg.ROBOTS[\"HEAVY\"].POWER_COST and \\\n",
    "        factory.cargo.metal >= self.env_cfg.ROBOTS[\"HEAVY\"].METAL_COST:\n",
    "            actions[unit_id] = factory.build_heavy()\n",
    "        factory_tiles += [factory.pos]\n",
    "        factory_units += [factory]\n",
    "    factory_tiles = np.array(factory_tiles)\n",
    "\n",
    "    units = game_state.units[self.player]\n",
    "    ice_map = game_state.board.ice\n",
    "    ice_tile_locations = np.argwhere(ice_map == 1)\n",
    "    for unit_id, unit in units.items():\n",
    "        \n",
    "        # track the closest factory\n",
    "        closest_factory = None\n",
    "        adjacent_to_factory = False\n",
    "        if len(factory_tiles) > 0:\n",
    "            factory_distances = np.mean((factory_tiles - unit.pos) ** 2, 1)\n",
    "            closest_factory_tile = factory_tiles[np.argmin(factory_distances)]\n",
    "            closest_factory = factory_units[np.argmin(factory_distances)]\n",
    "            adjacent_to_factory = np.mean((closest_factory_tile - unit.pos) ** 2) == 0\n",
    "        \n",
    "            # previous ice mining code\n",
    "            if unit.cargo.ice < 40:\n",
    "                ice_tile_distances = np.mean((ice_tile_locations - unit.pos) ** 2, 1)\n",
    "                closest_ice_tile = ice_tile_locations[np.argmin(ice_tile_distances)]\n",
    "                if np.all(closest_ice_tile == unit.pos):\n",
    "                    if unit.power >= unit.dig_cost(game_state) + unit.action_queue_cost(game_state):\n",
    "                        actions[unit_id] = [unit.dig(repeat=0)]\n",
    "                else:\n",
    "                    direction = direction_to(unit.pos, closest_ice_tile)\n",
    "                    move_cost = unit.move_cost(game_state, direction)\n",
    "                    if move_cost is not None and unit.power >= move_cost + unit.action_queue_cost(game_state):\n",
    "                        actions[unit_id] = [unit.move(direction, repeat=0)]\n",
    "            # else if we have enough ice, we go back to the factory and dump it.\n",
    "            elif unit.cargo.ice >= 40:\n",
    "                direction = direction_to(unit.pos, closest_factory_tile)\n",
    "                if adjacent_to_factory:\n",
    "                    if unit.power >= unit.action_queue_cost(game_state):\n",
    "                        actions[unit_id] = [unit.transfer(direction, 0, unit.cargo.ice, repeat=0)]\n",
    "                else:\n",
    "                    move_cost = unit.move_cost(game_state, direction)\n",
    "                    if move_cost is not None and unit.power >= move_cost + unit.action_queue_cost(game_state):\n",
    "                        actions[unit_id] = [unit.move(direction, repeat=0)]\n",
    "    return actions\n",
    "Agent.act = act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:46:04.547457Z",
     "iopub.status.busy": "2023-01-24T19:46:04.546378Z",
     "iopub.status.idle": "2023-01-24T19:46:37.196058Z",
     "shell.execute_reply": "2023-01-24T19:46:37.194690Z",
     "shell.execute_reply.started": "2023-01-24T19:46:04.547421Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# recreate our agents and run\n",
    "agents = {player: Agent(player, env.state.env_cfg) for player in env.agents}\n",
    "interact(env, agents, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Why does the green robot at bottom left never go to ice?_\n",
    "* _is the game above deterministic?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some factories are surviving for for more than 100 steps thanks to the delivery of additional ice, but more work will need to be done to keep them alive longer.\n",
    "\n",
    "Puting all those pieces together the full starter agent looks like this (and we will save it to agent.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:47:42.499658Z",
     "iopub.status.busy": "2023-01-24T19:47:42.499176Z",
     "iopub.status.idle": "2023-01-24T19:47:42.510391Z",
     "shell.execute_reply": "2023-01-24T19:47:42.509468Z",
     "shell.execute_reply.started": "2023-01-24T19:47:42.499624Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%writefile agent.py\n",
    "from lux.kit import obs_to_game_state, GameState, EnvConfig\n",
    "from lux.utils import direction_to, my_turn_to_place_factory\n",
    "import numpy as np\n",
    "import sys\n",
    "class Agent():\n",
    "    def __init__(self, player: str, env_cfg: EnvConfig) -> None:\n",
    "        self.player = player\n",
    "        self.opp_player = \"player_1\" if self.player == \"player_0\" else \"player_0\"\n",
    "        np.random.seed(0)\n",
    "        self.env_cfg: EnvConfig = env_cfg\n",
    "\n",
    "    def early_setup(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "        if step == 0:\n",
    "            # bid 0 to not waste resources bidding and declare as the default faction\n",
    "            return dict(faction=\"AlphaStrike\", bid=0)\n",
    "        else:\n",
    "            game_state = obs_to_game_state(step, self.env_cfg, obs)\n",
    "            # factory placement period\n",
    "\n",
    "            # how much water and metal you have in your starting pool to give to new factories\n",
    "            water_left = game_state.teams[self.player].water\n",
    "            metal_left = game_state.teams[self.player].metal\n",
    "\n",
    "            # how many factories you have left to place\n",
    "            factories_to_place = game_state.teams[self.player].factories_to_place\n",
    "            # whether it is your turn to place a factory\n",
    "            my_turn_to_place = my_turn_to_place_factory(game_state.teams[self.player].place_first, step)\n",
    "            if factories_to_place > 0 and my_turn_to_place:\n",
    "                # we will spawn our factory in a random location with 150 metal and water if it is our turn to place\n",
    "                potential_spawns = np.array(list(zip(*np.where(obs[\"board\"][\"valid_spawns_mask\"] == 1))))\n",
    "                spawn_loc = potential_spawns[np.random.randint(0, len(potential_spawns))]\n",
    "                return dict(spawn=spawn_loc, metal=150, water=150)\n",
    "            return dict()\n",
    "\n",
    "    def act(self, step: int, obs, remainingOverageTime: int = 60):\n",
    "        actions = dict()\n",
    "        game_state = obs_to_game_state(step, self.env_cfg, obs)\n",
    "        factories = game_state.factories[self.player]\n",
    "        game_state.teams[self.player].place_first\n",
    "        factory_tiles, factory_units = [], []\n",
    "        for unit_id, factory in factories.items():\n",
    "            if factory.power >= self.env_cfg.ROBOTS[\"HEAVY\"].POWER_COST and \\\n",
    "            factory.cargo.metal >= self.env_cfg.ROBOTS[\"HEAVY\"].METAL_COST:\n",
    "                actions[unit_id] = factory.build_heavy()\n",
    "            if self.env_cfg.max_episode_length - game_state.real_env_steps < 50:\n",
    "                if factory.water_cost(game_state) <= factory.cargo.water:\n",
    "                    actions[unit_id] = factory.water()\n",
    "            factory_tiles += [factory.pos]\n",
    "            factory_units += [factory]\n",
    "        factory_tiles = np.array(factory_tiles)\n",
    "\n",
    "        units = game_state.units[self.player]\n",
    "        ice_map = game_state.board.ice\n",
    "        ice_tile_locations = np.argwhere(ice_map == 1)\n",
    "        for unit_id, unit in units.items():\n",
    "\n",
    "            # track the closest factory\n",
    "            closest_factory = None\n",
    "            adjacent_to_factory = False\n",
    "            if len(factory_tiles) > 0:\n",
    "                factory_distances = np.mean((factory_tiles - unit.pos) ** 2, 1)\n",
    "                closest_factory_tile = factory_tiles[np.argmin(factory_distances)]\n",
    "                closest_factory = factory_units[np.argmin(factory_distances)]\n",
    "                adjacent_to_factory = np.mean((closest_factory_tile - unit.pos) ** 2) == 0\n",
    "\n",
    "                # previous ice mining code\n",
    "                if unit.cargo.ice < 40:\n",
    "                    ice_tile_distances = np.mean((ice_tile_locations - unit.pos) ** 2, 1)\n",
    "                    closest_ice_tile = ice_tile_locations[np.argmin(ice_tile_distances)]\n",
    "                    if np.all(closest_ice_tile == unit.pos):\n",
    "                        if unit.power >= unit.dig_cost(game_state) + unit.action_queue_cost(game_state):\n",
    "                            actions[unit_id] = [unit.dig(repeat=0)]\n",
    "                    else:\n",
    "                        direction = direction_to(unit.pos, closest_ice_tile)\n",
    "                        move_cost = unit.move_cost(game_state, direction)\n",
    "                        if move_cost is not None and unit.power >= move_cost + unit.action_queue_cost(game_state):\n",
    "                            actions[unit_id] = [unit.move(direction, repeat=0)]\n",
    "                # else if we have enough ice, we go back to the factory and dump it.\n",
    "                elif unit.cargo.ice >= 40:\n",
    "                    direction = direction_to(unit.pos, closest_factory_tile)\n",
    "                    if adjacent_to_factory:\n",
    "                        if unit.power >= unit.action_queue_cost(game_state):\n",
    "                            actions[unit_id] = [unit.transfer(direction, 0, unit.cargo.ice, repeat=0)]\n",
    "                    else:\n",
    "                        move_cost = unit.move_cost(game_state, direction)\n",
    "                        if move_cost is not None and unit.power >= move_cost + unit.action_queue_cost(game_state):\n",
    "                            actions[unit_id] = [unit.move(direction, repeat=0)]\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a submission\n",
    "Now we need to create a .tar.gz file with main.py (and agent.py) at the top level. We can then upload this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:48:00.139465Z",
     "iopub.status.busy": "2023-01-24T19:48:00.138997Z",
     "iopub.status.idle": "2023-01-24T19:48:01.471618Z",
     "shell.execute_reply": "2023-01-24T19:48:01.469711Z",
     "shell.execute_reply.started": "2023-01-24T19:48:00.139430Z"
    }
   },
   "outputs": [],
   "source": [
    "# !tar -czf submission.tar.gz *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit\n",
    "Now open the /kaggle/working folder and find submission.tar.gz, download that file, navigate to the \"MySubmissions\" tab in https://www.kaggle.com/c/lux-ai-season-2/ and upload your submission! It should play a validation match against itself and once it succeeds it will be automatically matched against other players' submissions. Newer submissions will be prioritized for games over older ones. Your team is limited in the number of succesful submissions per day so we highly recommend testing your bot locally before submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLI Tool\n",
    "\n",
    "To test your agent without using the python API you can also run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:48:30.388487Z",
     "iopub.status.busy": "2023-01-24T19:48:30.388006Z",
     "iopub.status.idle": "2023-01-24T19:48:37.207607Z",
     "shell.execute_reply": "2023-01-24T19:48:37.205935Z",
     "shell.execute_reply.started": "2023-01-24T19:48:30.388447Z"
    }
   },
   "outputs": [],
   "source": [
    "# !luxai-s2 main.py main.py -v 2 -s 101 -o replay.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which uses a random seed and generates a replay.html file that you can click and watch. Optionally if you specify `-o replay.json` you can upload replay.json to http://s2vis.lux-ai.org/.\n",
    "\n",
    "The CLI tool enables you to easily run episodes between any two agents (python or not) and provides a flexible tournament running tool to evaluate many agents together. Documentation on this tool can be found here: https://github.com/Lux-AI-Challenge/Lux-Design-S2/tree/main/luxai_runner/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-24T19:50:03.841109Z",
     "iopub.status.busy": "2023-01-24T19:50:03.840662Z",
     "iopub.status.idle": "2023-01-24T19:50:03.859821Z",
     "shell.execute_reply": "2023-01-24T19:50:03.858195Z",
     "shell.execute_reply.started": "2023-01-24T19:50:03.841075Z"
    }
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "# IPython.display.HTML(filename='replay.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lux310",
   "language": "python",
   "name": "lux310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "95c78092eaa97395644b547c35f355f36ca9b4a25bd2b7641e327063759a9b57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
